# DataFusion Ingest ‚Äì API Delta Pipeline

## üéØ Objetivo
Pipeline batch que consome dados da API CoinGecko, transforma com PySpark e armazena em Delta Lake. Orquestra√ß√£o via Airflow, monitoramento com Prometheus/Grafana, CI/CD e deploy automatizado.

## üöÄ Pr√©-requisitos

### Para execu√ß√£o local
- Docker 20.10+
- Docker Compose 2.0+
- 8GB+ de RAM recomendado
- 10GB+ de espa√ßo em disco

### Para deploy em produ√ß√£o (VPS/EC2)
- Ubuntu 20.04/22.04 LTS
- Docker e Docker Compose instalados
- 4GB+ de RAM (8GB recomendado)
- 20GB+ de espa√ßo em disco
- Portas 80, 443, 8080, 3000, 9090 liberadas

## üñ•Ô∏è Execu√ß√£o Local

1. **Clone o reposit√≥rio**
   ```bash
   git clone https://github.com/mydatafusionx/coingecko-ingest.git
   cd coingecko-ingest
   ```

2. **Configure as vari√°veis de ambiente**
   ```bash
   cp .env.example .env
   # Edite o arquivo .env conforme necess√°rio
   ```

3. **Inicie os containers**
   ```bash
   docker-compose up --build -d
   ```

4. **Acesse os servi√ßos**
   - Airflow: http://localhost:8080 (usu√°rio: `airflow`, senha: `airflow`)
   - Spark UI: http://localhost:4040
   - Prometheus: http://localhost:9090
   - Grafana: http://localhost:3000 (usu√°rio: `admin`, senha: `admin`)

## ‚òÅÔ∏è Deploy em Produ√ß√£o (VPS/EC2)

### 1. Configura√ß√£o Inicial do Servidor

```bash
# Atualize o sistema
sudo apt update && sudo apt upgrade -y

# Instale pr√©-requisitos
sudo apt install -y git docker.io docker-compose

# Adicione seu usu√°rio ao grupo docker
sudo usermod -aG docker $USER
newgrp docker
```

### 2. Implanta√ß√£o Manual

```bash
# Clone o reposit√≥rio
mkdir -p /opt/coingecko-ingest
cd /opt/coingecko-ingest
git clone https://github.com/mydatafusionx/coingecko-ingest.git .

# Configure as vari√°veis de ambiente
cp .env.example .env
nano .env  # Edite conforme necess√°rio

# Crie diret√≥rios de dados
mkdir -p data/raw data/delta

# Inicie os containers
docker-compose up --build -d
```

### 3. Configura√ß√£o do Nginx (Opcional, para HTTPS)

```bash
# Instale o Nginx
sudo apt install -y nginx

# Configure o proxy reverso
sudo nano /etc/nginx/sites-available/coingecko
```

Adicione a configura√ß√£o do Nginx (substitua `SEU_DOMINIO`):

```nginx
server {
    listen 80;
    server_name SEU_DOMINIO;

    location / {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}
```

Ative o site e recarregue o Nginx:
```bash
sudo ln -s /etc/nginx/sites-available/coingecko /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

### 4. Atualiza√ß√£o Autom√°tica (CI/CD)

1. **Configure as secrets no GitHub** (Settings > Secrets > Actions):
   - `DEPLOY_HOST`: Endere√ßo do seu servidor
   - `DEPLOY_USER`: Usu√°rio SSH
   - `DEPLOY_KEY`: Chave privada SSH

2. **Ative o workflow de CI/CD**
   - O workflow j√° est√° configurado no reposit√≥rio
   - Push na branch `main` dispara o deploy autom√°tico

## üîß Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ airflow/               # Configura√ß√µes do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dags/             # DAGs do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile        # Imagem personalizada
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt  # Depend√™ncias Python
‚îú‚îÄ‚îÄ java-client/          # Cliente Java para API CoinGecko
‚îú‚îÄ‚îÄ spark/                # Scripts PySpark
‚îÇ   ‚îî‚îÄ‚îÄ transform.py      # Transforma√ß√£o de dados
‚îú‚îÄ‚îÄ monitoring/           # Configura√ß√µes de monitoramento
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/       # Configura√ß√£o do Prometheus
‚îÇ   ‚îî‚îÄ‚îÄ grafana/          # Dashboards e configura√ß√µes
‚îú‚îÄ‚îÄ data/                 # Dados (n√£o versionado)
‚îÇ   ‚îú‚îÄ‚îÄ raw/             # Dados brutos da API
‚îÇ   ‚îî‚îÄ‚îÄ delta/           # Dados processados (Delta Lake)
‚îú‚îÄ‚îÄ docker-compose.yml    # Orquestra√ß√£o de containers
‚îî‚îÄ‚îÄ README.md            # Este arquivo
```

## üîÑ Fluxo de Dados

1. **Extra√ß√£o**: Cliente Java consome a API CoinGecko
2. **Armazenamento Bruto**: Dados salvos em JSON no diret√≥rio `data/raw`
3. **Transforma√ß√£o**: PySpark processa e converte para Delta Lake
4. **Armazenamento**: Dados estruturados em Delta Lake (`data/delta`)
5. **Monitoramento**: M√©tricas coletadas pelo Prometheus e visualizadas no Grafana

## üîç Acesso aos Dados

Os dados processados est√£o dispon√≠veis em `data/delta/` no formato Delta Lake. Para acess√°-los:

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("DeltaRead") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
    .getOrCreate()

df = spark.read.format("delta").load("data/delta/market_prices")
df.show()
```

## üìä Monitoramento com Grafana

O Grafana √© uma ferramenta poderosa para visualiza√ß√£o de m√©tricas e logs. Neste projeto, ele √© pr√©-configurado para monitorar o Airflow, Spark e m√©tricas do sistema.

### Acessando o Grafana

1. **Localmente**: Acesse http://localhost:3000
2. **Em produ√ß√£o**: Acesse `http://seu-dominio:3000` (ou a porta configurada)

**Credenciais padr√£o**:
- Usu√°rio: `admin`
- Senha: `admin` (ser√° solicitado altera√ß√£o no primeiro acesso)

### Configurando Fontes de Dados

1. **Prometheus** (j√° pr√©-configurado):
   - Nome: `Prometheus`
   - URL: `http://prometheus:9090`
   - Access: `Server`

2. **Loki** (para logs, se configurado):
   - Nome: `Loki`
   - URL: `http://loki:3100`
   - Access: `Server`

### Dashboards Importantes

1. **Airflow Metrics**
   - Monitora execu√ß√£o de DAGs e tarefas
   - M√©tricas de sucesso/falha
   - Tempo de execu√ß√£o das tarefas

2. **Spark Monitoring**
   - Uso de recursos (CPU, mem√≥ria)
   - Execu√ß√£o de jobs e est√°gios
   - Throughput de processamento

3. **System Metrics**
   - Uso de CPU, mem√≥ria e disco
   - Rede e E/S
   - Uso de containers Docker

### Criando um Novo Dashboard

1. Clique em "+" > "Create" > "Dashboard"
2. Adicione um novo painel clicando em "Add panel"
3. Selecione a fonte de dados (ex: Prometheus)
4. Use PromQL para criar suas consultas, por exemplo:
   ```
   # Taxa de sucesso das DAGs
   rate(airflow_dagrun_duration_success[5m])
   
   # Uso de mem√≥ria do Spark
   jvm_memory_bytes_used{container_label_com_docker_compose_service="spark-worker"}
   ```
5. Personalize a visualiza√ß√£o (gr√°fico, tabela, etc.)

### Alertas no Grafana

1. V√° em "Alert" > "Alert rules" > "New alert rule"
2. Defina a condi√ß√£o de alerta (ex: mem√≥ria > 90% por 5 minutos)
3. Configure os canais de notifica√ß√£o (Email, Slack, etc.)

### Dicas de Uso

- Use vari√°veis de dashboard para criar filtros reutiliz√°veis
- Exporte/importe dashboards para backup ou compartilhamento
- Configure permiss√µes de usu√°rio para controle de acesso

## üìä Outras Ferramentas de Monitoramento

- **Airflow UI**: Monitoramento de DAGs e tarefas
- **Prometheus**: Consulta detalhada de m√©tricas
- **Spark UI**: Monitoramento de jobs Spark
- **Grafana Logs**: Visualiza√ß√£o centralizada de logs

## üîÑ Manuten√ß√£o

### Atualizando o Projeto

```bash
# No servidor de produ√ß√£o
cd /opt/coingecko-ingest
git pull
docker-compose up --build -d
```

### Limpando Dados Antigos

```bash
# Limpar dados antigos (cuidado!)
docker-compose down -v
```

## üìù Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Por favor, leia nosso [guia de contribui√ß√£o](CONTRIBUTING.md) para detalhes sobre como enviar pull requests.

---

Desenvolvido por [Seu Nome] - [Seu Site] - [Seu Email]
